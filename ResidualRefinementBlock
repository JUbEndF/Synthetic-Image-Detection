digraph {
	graph [size="21.9,21.9"]
	node [align=left fontname=monospace fontsize=50 height=0.2 ranksep=0.1 shape=box style=filled]
	2153705342448 [label="
 (1, 3, 256, 256)" fillcolor=darkolivegreen1]
	2153705357376 [label=ConvolutionBackward0]
	2153705357520 -> 2153705357376
	2153705357520 [label=CatBackward0]
	2153705357712 -> 2153705357520
	2153705357712 [label=MulBackward0]
	2153705357856 -> 2153705357712
	2153705357856 [label=ConvolutionBackward0]
	2153705358000 -> 2153705357856
	2153705358000 [label=ReluBackward0]
	2153705358192 -> 2153705358000
	2153705358192 [label=ConvolutionBackward0]
	2153705358288 -> 2153705358192
	2153704961616 [label="dab_block1.conv1.weight
 (3, 3, 3, 3)" fillcolor=lightblue]
	2153704961616 -> 2153705358288
	2153705358288 [label=AccumulateGrad]
	2153705358240 -> 2153705358192
	2153704961712 [label="dab_block1.conv1.bias
 (3)" fillcolor=lightblue]
	2153704961712 -> 2153705358240
	2153705358240 [label=AccumulateGrad]
	2153705357952 -> 2153705357856
	2153704961808 [label="dab_block1.conv2.weight
 (3, 3, 3, 3)" fillcolor=lightblue]
	2153704961808 -> 2153705357952
	2153705357952 [label=AccumulateGrad]
	2153705357904 -> 2153705357856
	2153704961904 [label="dab_block1.conv2.bias
 (3)" fillcolor=lightblue]
	2153704961904 -> 2153705357904
	2153705357904 [label=AccumulateGrad]
	2153705357808 -> 2153705357712
	2153705357808 [label=SigmoidBackward0]
	2153705358096 -> 2153705357808
	2153705358096 [label=MulBackward0]
	2153705358384 -> 2153705358096
	2153705358384 [label=ConvolutionBackward0]
	2153705358528 -> 2153705358384
	2153705358528 [label=ReluBackward0]
	2153705358720 -> 2153705358528
	2153705358720 [label=ConvolutionBackward0]
	2153705358816 -> 2153705358720
	2153705358816 [label=MeanBackward1]
	2153705357856 -> 2153705358816
	2153705358768 -> 2153705358720
	2153704962000 [label="dab_block1.att_conv1.weight
 (3, 3, 1, 1)" fillcolor=lightblue]
	2153704962000 -> 2153705358768
	2153705358768 [label=AccumulateGrad]
	2153705358624 -> 2153705358720
	2153704962096 [label="dab_block1.att_conv1.bias
 (3)" fillcolor=lightblue]
	2153704962096 -> 2153705358624
	2153705358624 [label=AccumulateGrad]
	2153705358480 -> 2153705358384
	2153704962192 [label="dab_block1.att_conv2.weight
 (3, 3, 1, 1)" fillcolor=lightblue]
	2153704962192 -> 2153705358480
	2153705358480 [label=AccumulateGrad]
	2153705358432 -> 2153705358384
	2153704962288 [label="dab_block1.att_conv2.bias
 (3)" fillcolor=lightblue]
	2153704962288 -> 2153705358432
	2153705358432 [label=AccumulateGrad]
	2153705358336 -> 2153705358096
	2153705358336 [label=ConvolutionBackward0]
	2153705358864 -> 2153705358336
	2153705358864 [label=ReluBackward0]
	2153705358960 -> 2153705358864
	2153705358960 [label=ConvolutionBackward0]
	2153705359056 -> 2153705358960
	2153705359056 [label=AdaptiveMaxPool2DBackward0]
	2153705357856 -> 2153705359056
	2153705358768 -> 2153705358960
	2153705358624 -> 2153705358960
	2153705358480 -> 2153705358336
	2153705358432 -> 2153705358336
	2153705357424 -> 2153705357520
	2153705357424 [label=MulBackward0]
	2153705358048 -> 2153705357424
	2153705358048 [label=ConvolutionBackward0]
	2153705358912 -> 2153705358048
	2153705358912 [label=ReluBackward0]
	2153705359200 -> 2153705358912
	2153705359200 [label=ConvolutionBackward0]
	2153705357712 -> 2153705359200
	2153705359296 -> 2153705359200
	2153704962384 [label="dab_block2.conv1.weight
 (3, 3, 3, 3)" fillcolor=lightblue]
	2153704962384 -> 2153705359296
	2153705359296 [label=AccumulateGrad]
	2153705359248 -> 2153705359200
	2153704962480 [label="dab_block2.conv1.bias
 (3)" fillcolor=lightblue]
	2153704962480 -> 2153705359248
	2153705359248 [label=AccumulateGrad]
	2153705359008 -> 2153705358048
	2153704962576 [label="dab_block2.conv2.weight
 (3, 3, 3, 3)" fillcolor=lightblue]
	2153704962576 -> 2153705359008
	2153705359008 [label=AccumulateGrad]
	2153705358672 -> 2153705358048
	2153704962672 [label="dab_block2.conv2.bias
 (3)" fillcolor=lightblue]
	2153704962672 -> 2153705358672
	2153705358672 [label=AccumulateGrad]
	2153705358144 -> 2153705357424
	2153705358144 [label=SigmoidBackward0]
	2153705359104 -> 2153705358144
	2153705359104 [label=MulBackward0]
	2153705359392 -> 2153705359104
	2153705359392 [label=ConvolutionBackward0]
	2153705359536 -> 2153705359392
	2153705359536 [label=ReluBackward0]
	2153705359728 -> 2153705359536
	2153705359728 [label=ConvolutionBackward0]
	2153705359824 -> 2153705359728
	2153705359824 [label=MeanBackward1]
	2153705358048 -> 2153705359824
	2153705359776 -> 2153705359728
	2153704962768 [label="dab_block2.att_conv1.weight
 (3, 3, 1, 1)" fillcolor=lightblue]
	2153704962768 -> 2153705359776
	2153705359776 [label=AccumulateGrad]
	2153705359632 -> 2153705359728
	2153704962864 [label="dab_block2.att_conv1.bias
 (3)" fillcolor=lightblue]
	2153704962864 -> 2153705359632
	2153705359632 [label=AccumulateGrad]
	2153705359488 -> 2153705359392
	2153704962960 [label="dab_block2.att_conv2.weight
 (3, 3, 1, 1)" fillcolor=lightblue]
	2153704962960 -> 2153705359488
	2153705359488 [label=AccumulateGrad]
	2153705359440 -> 2153705359392
	2153704963056 [label="dab_block2.att_conv2.bias
 (3)" fillcolor=lightblue]
	2153704963056 -> 2153705359440
	2153705359440 [label=AccumulateGrad]
	2153705359344 -> 2153705359104
	2153705359344 [label=ConvolutionBackward0]
	2153705359872 -> 2153705359344
	2153705359872 [label=ReluBackward0]
	2153705359968 -> 2153705359872
	2153705359968 [label=ConvolutionBackward0]
	2153705360064 -> 2153705359968
	2153705360064 [label=AdaptiveMaxPool2DBackward0]
	2153705358048 -> 2153705360064
	2153705359776 -> 2153705359968
	2153705359632 -> 2153705359968
	2153705359488 -> 2153705359344
	2153705359440 -> 2153705359344
	2153705357568 -> 2153705357376
	2153704963152 [label="conv_merge.weight
 (3, 6, 1, 1)" fillcolor=lightblue]
	2153704963152 -> 2153705357568
	2153705357568 [label=AccumulateGrad]
	2153705357616 -> 2153705357376
	2153704963248 [label="conv_merge.bias
 (3)" fillcolor=lightblue]
	2153704963248 -> 2153705357616
	2153705357616 [label=AccumulateGrad]
	2153705357376 -> 2153705342448
}
