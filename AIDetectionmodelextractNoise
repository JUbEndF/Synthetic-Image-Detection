digraph {
	graph [size="25.2,25.2"]
	node [align=left fontname=monospace fontsize=50 height=0.2 ranksep=0.1 shape=box style=filled]
	1629539862480 [label="
 (1, 3, 256, 256)" fillcolor=darkolivegreen1]
	1629539877120 [label=SubBackward0]
	1629539877264 -> 1629539877120
	1629539877264 [label=ConvolutionBackward0]
	1629539877408 -> 1629539877264
	1629539877408 [label=ConvolutionBackward0]
	1629539877552 -> 1629539877408
	1629539877552 [label=CatBackward0]
	1629539877744 -> 1629539877552
	1629539877744 [label=MulBackward0]
	1629539877888 -> 1629539877744
	1629539877888 [label=ConvolutionBackward0]
	1629539878032 -> 1629539877888
	1629539878032 [label=ReluBackward0]
	1629539878224 -> 1629539878032
	1629539878224 [label=ConvolutionBackward0]
	1629539878320 -> 1629539878224
	1629539878320 [label=ConvolutionBackward0]
	1629539878512 -> 1629539878320
	1629539448208 [label="conv_input.weight
 (32, 3, 3, 3)" fillcolor=lightblue]
	1629539448208 -> 1629539878512
	1629539878512 [label=AccumulateGrad]
	1629539878464 -> 1629539878320
	1629539448304 [label="conv_input.bias
 (32)" fillcolor=lightblue]
	1629539448304 -> 1629539878464
	1629539878464 [label=AccumulateGrad]
	1629539878272 -> 1629539878224
	1629539448400 [label="rrg_blocks.0.dab_block1.conv1.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1629539448400 -> 1629539878272
	1629539878272 [label=AccumulateGrad]
	1629539878128 -> 1629539878224
	1629539448496 [label="rrg_blocks.0.dab_block1.conv1.bias
 (32)" fillcolor=lightblue]
	1629539448496 -> 1629539878128
	1629539878128 [label=AccumulateGrad]
	1629539877984 -> 1629539877888
	1629539448592 [label="rrg_blocks.0.dab_block1.conv2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1629539448592 -> 1629539877984
	1629539877984 [label=AccumulateGrad]
	1629539877936 -> 1629539877888
	1629539448688 [label="rrg_blocks.0.dab_block1.conv2.bias
 (32)" fillcolor=lightblue]
	1629539448688 -> 1629539877936
	1629539877936 [label=AccumulateGrad]
	1629539877840 -> 1629539877744
	1629539877840 [label=SigmoidBackward0]
	1629539878368 -> 1629539877840
	1629539878368 [label=MulBackward0]
	1629539878560 -> 1629539878368
	1629539878560 [label=ConvolutionBackward0]
	1629539878704 -> 1629539878560
	1629539878704 [label=ReluBackward0]
	1629539878896 -> 1629539878704
	1629539878896 [label=ConvolutionBackward0]
	1629539878992 -> 1629539878896
	1629539878992 [label=MeanBackward1]
	1629539877888 -> 1629539878992
	1629539878944 -> 1629539878896
	1629539448784 [label="rrg_blocks.0.dab_block1.att_conv1.weight
 (32, 32, 1, 1)" fillcolor=lightblue]
	1629539448784 -> 1629539878944
	1629539878944 [label=AccumulateGrad]
	1629539878800 -> 1629539878896
	1629539448880 [label="rrg_blocks.0.dab_block1.att_conv1.bias
 (32)" fillcolor=lightblue]
	1629539448880 -> 1629539878800
	1629539878800 [label=AccumulateGrad]
	1629539878656 -> 1629539878560
	1629539448976 [label="rrg_blocks.0.dab_block1.att_conv2.weight
 (32, 32, 1, 1)" fillcolor=lightblue]
	1629539448976 -> 1629539878656
	1629539878656 [label=AccumulateGrad]
	1629539878608 -> 1629539878560
	1629539449072 [label="rrg_blocks.0.dab_block1.att_conv2.bias
 (32)" fillcolor=lightblue]
	1629539449072 -> 1629539878608
	1629539878608 [label=AccumulateGrad]
	1629539878416 -> 1629539878368
	1629539878416 [label=ConvolutionBackward0]
	1629539879040 -> 1629539878416
	1629539879040 [label=ReluBackward0]
	1629539879136 -> 1629539879040
	1629539879136 [label=ConvolutionBackward0]
	1629539879232 -> 1629539879136
	1629539879232 [label=AdaptiveMaxPool2DBackward0]
	1629539877888 -> 1629539879232
	1629539878944 -> 1629539879136
	1629539878800 -> 1629539879136
	1629539878656 -> 1629539878416
	1629539878608 -> 1629539878416
	1629539877696 -> 1629539877552
	1629539877696 [label=MulBackward0]
	1629539878080 -> 1629539877696
	1629539878080 [label=ConvolutionBackward0]
	1629539879088 -> 1629539878080
	1629539879088 [label=ReluBackward0]
	1629539879376 -> 1629539879088
	1629539879376 [label=ConvolutionBackward0]
	1629539877744 -> 1629539879376
	1629539879472 -> 1629539879376
	1629539449168 [label="rrg_blocks.0.dab_block2.conv1.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1629539449168 -> 1629539879472
	1629539879472 [label=AccumulateGrad]
	1629539879424 -> 1629539879376
	1629539449264 [label="rrg_blocks.0.dab_block2.conv1.bias
 (32)" fillcolor=lightblue]
	1629539449264 -> 1629539879424
	1629539879424 [label=AccumulateGrad]
	1629539879184 -> 1629539878080
	1629539449360 [label="rrg_blocks.0.dab_block2.conv2.weight
 (32, 32, 3, 3)" fillcolor=lightblue]
	1629539449360 -> 1629539879184
	1629539879184 [label=AccumulateGrad]
	1629539878848 -> 1629539878080
	1629539449456 [label="rrg_blocks.0.dab_block2.conv2.bias
 (32)" fillcolor=lightblue]
	1629539449456 -> 1629539878848
	1629539878848 [label=AccumulateGrad]
	1629539878176 -> 1629539877696
	1629539878176 [label=SigmoidBackward0]
	1629539879280 -> 1629539878176
	1629539879280 [label=MulBackward0]
	1629539879568 -> 1629539879280
	1629539879568 [label=ConvolutionBackward0]
	1629539879712 -> 1629539879568
	1629539879712 [label=ReluBackward0]
	1629539879904 -> 1629539879712
	1629539879904 [label=ConvolutionBackward0]
	1629539880000 -> 1629539879904
	1629539880000 [label=MeanBackward1]
	1629539878080 -> 1629539880000
	1629539879952 -> 1629539879904
	1629539449552 [label="rrg_blocks.0.dab_block2.att_conv1.weight
 (32, 32, 1, 1)" fillcolor=lightblue]
	1629539449552 -> 1629539879952
	1629539879952 [label=AccumulateGrad]
	1629539879808 -> 1629539879904
	1629539449648 [label="rrg_blocks.0.dab_block2.att_conv1.bias
 (32)" fillcolor=lightblue]
	1629539449648 -> 1629539879808
	1629539879808 [label=AccumulateGrad]
	1629539879664 -> 1629539879568
	1629539449744 [label="rrg_blocks.0.dab_block2.att_conv2.weight
 (32, 32, 1, 1)" fillcolor=lightblue]
	1629539449744 -> 1629539879664
	1629539879664 [label=AccumulateGrad]
	1629539879616 -> 1629539879568
	1629539449840 [label="rrg_blocks.0.dab_block2.att_conv2.bias
 (32)" fillcolor=lightblue]
	1629539449840 -> 1629539879616
	1629539879616 [label=AccumulateGrad]
	1629539879520 -> 1629539879280
	1629539879520 [label=ConvolutionBackward0]
	1629539880048 -> 1629539879520
	1629539880048 [label=ReluBackward0]
	1629539880144 -> 1629539880048
	1629539880144 [label=ConvolutionBackward0]
	1629539880240 -> 1629539880144
	1629539880240 [label=AdaptiveMaxPool2DBackward0]
	1629539878080 -> 1629539880240
	1629539879952 -> 1629539880144
	1629539879808 -> 1629539880144
	1629539879664 -> 1629539879520
	1629539879616 -> 1629539879520
	1629539877504 -> 1629539877408
	1629539449936 [label="rrg_blocks.0.conv_merge.weight
 (32, 64, 1, 1)" fillcolor=lightblue]
	1629539449936 -> 1629539877504
	1629539877504 [label=AccumulateGrad]
	1629539877456 -> 1629539877408
	1629539450032 [label="rrg_blocks.0.conv_merge.bias
 (32)" fillcolor=lightblue]
	1629539450032 -> 1629539877456
	1629539877456 [label=AccumulateGrad]
	1629539877216 -> 1629539877264
	1629539450128 [label="conv_output.weight
 (3, 32, 3, 3)" fillcolor=lightblue]
	1629539450128 -> 1629539877216
	1629539877216 [label=AccumulateGrad]
	1629539877360 -> 1629539877264
	1629539450224 [label="conv_output.bias
 (3)" fillcolor=lightblue]
	1629539450224 -> 1629539877360
	1629539877360 [label=AccumulateGrad]
	1629539877120 -> 1629539862480
}
